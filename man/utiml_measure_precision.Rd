% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/measures.R
\name{utiml_measure_precision}
\alias{utiml_measure_precision}
\title{Compute the precision measure for binary classification}
\usage{
utiml_measure_precision(expected, predict)
}
\arguments{
\item{expected}{The expected list values (only 0 and 1)}

\item{predict}{The predicted list values (only 0 and 1)}
}
\value{
The precision in the 0..1 interval
}
\description{
Precision (also called positive predictive value)
 is the fraction of retrieved instances that are relevant. In
 other words, is the number of true positives (items correctly
 labeled as belonging to the positive class) divided by the
 total number of elements labeled as belonging to the positive
 class.
}
\examples{
utiml_measure_precision(c(1,1,1,0,0), c(1,1,0,0,0)) # 1
utiml_measure_precision(c(1,1,1,0,0), c(1,1,0,1,1)) # 0.5
utiml_measure_precision(c(1,1,1,0,0), c(0,0,0,1,1)) # 0

# No predicted positive values the result is a NaN
utiml_measure_precision(c(1,1,1,0,0), c(0,0,0,0,0))

# No expected positive values the result always is 0
utiml_measure_precision(c(0,0,0,0,0), c(0,1,1,0,0))
}

